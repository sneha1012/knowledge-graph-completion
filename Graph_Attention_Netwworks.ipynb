{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPA/NrVhML5mWOc9pdOTSh9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sneha1012/knowledge-graph-completion/blob/main/Graph_Attention_Netwworks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph attention Networks for knowledge completion graphs using Pytorch**\n",
        "\n",
        "Graph Attention Networks (GAT) Graph Attention Networks (GAT) introduce an attention mechanism that allows nodes to focus on their most informative neighbors, rather than treating all neighbors equally. This is particularly useful for graph-structured data where the importance of neighbors can vary significantly.\n",
        "\n",
        "we are using **Freebase 15k-237** Dataset present.\n",
        "**Origin**: Derived from Freebase and contains a subset of the FB15K dataset. **Textual Mentions**: Derived from 200 million sentences from the ClueWeb12 corpus coupled with Freebase entity mention annotations."
      ],
      "metadata": {
        "id": "695sd6VVJz-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision networkx matplotlib\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRxq8cpHKJKB",
        "outputId": "8dd59ca2-51cf-4425-b445-8910b7adc39d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/My Drive/Data for GATS/train.txt'\n",
        "\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    data = file.read()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5j2eJhzKQwn",
        "outputId": "d11149a2-e690-4a62-d553-73a3e874d7df"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionaries to map entities and relations to unique integer IDs\n",
        "entity2id = {}\n",
        "relation2id = {}\n",
        "\n",
        "# Lists to store triples\n",
        "triples = []\n",
        "\n",
        "# Read the file and process the data\n",
        "with open(file_path, 'r') as f:\n",
        "    for line in f:\n",
        "        s, p, o = line.strip().split('\\t')\n",
        "\n",
        "        # Assign unique IDs to entities and relations\n",
        "        if s not in entity2id:\n",
        "            entity2id[s] = len(entity2id)\n",
        "        if o not in entity2id:\n",
        "            entity2id[o] = len(entity2id)\n",
        "        if p not in relation2id:\n",
        "            relation2id[p] = len(relation2id)\n",
        "\n",
        "        # Store the triples\n",
        "        triples.append((entity2id[s], relation2id[p], entity2id[o]))"
      ],
      "metadata": {
        "id": "-Px8zEQjKtwP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining our GAT Model\n",
        "class GraphAttentionLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout, alpha, concat=True):\n",
        "        super(GraphAttentionLayer, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.alpha = alpha\n",
        "        self.concat = concat\n",
        "\n",
        "        self.W = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.a = nn.Linear(2*out_features, 1, bias=False)\n",
        "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
        "\n",
        "    def forward(self, input, adj):\n",
        "        h = self.W(input)\n",
        "        N = h.size()[0]\n",
        "        a_input = torch.cat([h.repeat(1, N).view(N * N, -1), h.repeat(N, 1)], dim=1).view(N, -1, 2 * self.out_features)\n",
        "        e = self.leakyrelu(self.a(a_input).squeeze(2))\n",
        "\n",
        "        zero_vec = -9e15*torch.ones_like(e)\n",
        "        attention = torch.where(adj > 0, e, zero_vec)\n",
        "        attention = F.softmax(attention, dim=1)\n",
        "        attention = F.dropout(attention, self.dropout, training=self.training)\n",
        "        h_prime = torch.matmul(attention, h)\n",
        "\n",
        "        if self.concat:\n",
        "            return F.elu(h_prime)\n",
        "        else:\n",
        "            return h_prime\n",
        "\n",
        "class GAT(nn.Module):\n",
        "    def __init__(self, nfeat, nhid, nclass, dropout, alpha, nheads):\n",
        "        super(GAT, self).__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.attentions = [GraphAttentionLayer(nfeat, nhid, dropout=dropout, alpha=alpha, concat=True) for _ in range(nheads)]\n",
        "        for i, attention in enumerate(self.attentions):\n",
        "            self.add_module('attention_{}'.format(i), attention)\n",
        "\n",
        "        self.out_att = GraphAttentionLayer(nhid * nheads, nclass, dropout=dropout, alpha=alpha, concat=False)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = torch.cat([att(x, adj) for att in self.attentions], dim=1)\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = F.elu(self.out_att(x, adj))\n",
        "        return x"
      ],
      "metadata": {
        "id": "vwXrVCzdKySb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_entities = len(entity2id)  # Number of unique entities in your dataset\n",
        "embedding_dim = 128  # Dimension of the embeddings\n",
        "\n",
        "# Create random initial embeddings for each entity\n",
        "initial_entity_embeddings = np.random.rand(num_entities, embedding_dim)\n",
        "initial_entity_embeddings_tensor = torch.tensor(initial_entity_embeddings, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "AdtK1qcJK-7T"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the matrix\n",
        "adjacency_matrix = torch.zeros((num_entities, num_entities))\n",
        "\n",
        "for s, _, o in triples:\n",
        "    adjacency_matrix[s][o] = 1\n",
        "    adjacency_matrix[o][s] = 1  # Assuming the graph is undirected"
      ],
      "metadata": {
        "id": "8g-XjsbvLEa1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.Graph()\n",
        "for s, p, o in triples:\n",
        "    G.add_edge(s, o, label=p)\n",
        "\n",
        "pos = nx.spring_layout(G)\n",
        "plt.figure(figsize=(12, 12))\n",
        "nx.draw(G, pos, with_labels=True, node_size=500, node_color=\"skyblue\", font_size=10, font_color=\"k\")\n",
        "plt.title(\"Graph Representation\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DR2R9C_YLJta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "nhid = 8  # Number of hidden units\n",
        "nclass = embedding_dim  # Output class, this can be adjusted considering our task we tring to achieve\n",
        "dropout = 0.6  # Dropout rate\n",
        "alpha = 0.2  # Alpha for the leaky_relu\n",
        "nheads = 8  # Number of head attentions\n",
        "\n",
        "# Initialize the GAT model and optimizer\n",
        "model = GAT(nfeat=embedding_dim, nhid=nhid, nclass=nclass, dropout=dropout, alpha=alpha, nheads=nheads)\n",
        "optimizer = Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "\n",
        "# Placeholder for the labels (you'll need to define this based on your task)\n",
        "labels = torch.tensor(initial_entity_embeddings, dtype=torch.float32)\n",
        "\n",
        "# Training loop\n",
        "epochs = 200\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(initial_entity_embeddings_tensor, adjacency_matrix)\n",
        "\n",
        "    # Computing the loss here\n",
        "    loss_train = F.mse_loss(output, labels)  # Using MSE loss as a placeholder\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n"
      ],
      "metadata": {
        "id": "YtTKL2mwLL6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract embeddings after training\n",
        "embeddings = model(initial_entity_embeddings_tensor, adjacency_matrix).detach().numpy()\n",
        "\n",
        "# Apply t-SNE\n",
        "tsne = TSNE(n_components=2)\n",
        "embeddings_2d = tsne.fit_transform(embeddings)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1])\n",
        "plt.title(\"2D t-SNE representation of embeddings\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "25CIFzU9LPHU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}